[2025-01-13 17:40:35,209][__main__][INFO] - Logger is configured correctly.
[2025-01-13 17:40:35,405][nuplan.planning.script.builders.folder_builder][INFO] - Building experiment folders...
[2025-01-13 17:40:35,405][nuplan.planning.script.builders.folder_builder][INFO] - Experimental folder: /data/datasets/niukangjia/plantf/output/training/planTF/2025.01.13.17.40.33
[2025-01-13 17:40:35,406][nuplan.planning.script.builders.worker_pool_builder][INFO] - Building WorkerPool...
[2025-01-13 17:40:35,406][nuplan.planning.utils.multithreading.worker_pool][INFO] - Worker: SingleMachineParallelExecutor
[2025-01-13 17:40:35,407][nuplan.planning.utils.multithreading.worker_pool][INFO] - Number of nodes: 1
Number of CPUs per node: 32
Number of GPUs per node: 0
Number of threads across all nodes: 32
[2025-01-13 17:40:35,407][nuplan.planning.script.builders.worker_pool_builder][INFO] - Building WorkerPool...DONE!
[2025-01-13 17:40:35,407][src.custom_training.custom_training_builder][INFO] - Building training engine...
[2025-01-13 17:40:40,140][nuplan.planning.script.builders.model_builder][INFO] - Building TorchModuleWrapper...
[2025-01-13 17:40:41,185][nuplan.planning.script.builders.model_builder][INFO] - Building TorchModuleWrapper...DONE!
[2025-01-13 17:40:41,186][nuplan.planning.script.builders.splitter_builder][INFO] - Building Splitter...
[2025-01-13 17:40:41,992][nuplan.planning.script.builders.splitter_builder][INFO] - Building Splitter...DONE!
[2025-01-13 17:40:41,993][nuplan.planning.script.builders.data_augmentation_builder][INFO] - Building augmentors...
[2025-01-13 17:40:41,995][nuplan.planning.script.builders.data_augmentation_builder][INFO] - Building augmentors...DONE!
[2025-01-13 17:40:54,957][nuplan.planning.script.builders.scenario_builder][INFO] - Extracted 204791 scenarios for training
[2025-01-13 17:40:54,961][__main__][INFO] - Starting training...
[2025-01-13 17:40:55,003][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:1 to store for rank: 0
[2025-01-13 17:40:55,003][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.
[2025-01-13 17:40:55,435][src.custom_training.custom_datamodule][INFO] - Number of samples in train set: 132384
[2025-01-13 17:40:55,519][src.custom_training.custom_datamodule][INFO] - Number of samples in validation set: 32407
[2025-01-13 17:40:59,286][root][INFO] - 
[Epoch 0] val_loss: 10.29821, val_reg_loss: 4.51069, val_cls_loss: 2.21845, val_prediction_losss: 3.11027, val_diffusion_loss: 0.45879, val_MR: 0.68750, val_minADE1: 17.51128, val_minADE6: 17.48439, val_minFDE1: 34.75602, val_minFDE6: 34.50874
[2025-01-13 17:58:28,235][root][INFO] - 
[Epoch 0] val_loss: 8.39667, val_reg_loss: 3.35382, val_cls_loss: 1.00544, val_prediction_losss: 2.49881, val_diffusion_loss: 1.53860, val_MR: 0.70726, val_minADE1: 13.32812, val_minADE6: 13.09350, val_minFDE1: 29.85258, val_minFDE6: 29.54158
[2025-01-13 18:15:43,045][root][INFO] - 
[Epoch 0] val_loss: 8.11075, val_reg_loss: 2.99874, val_cls_loss: 0.95787, val_prediction_losss: 2.08224, val_diffusion_loss: 2.07191, val_MR: 0.68846, val_minADE1: 12.07320, val_minADE6: 11.76355, val_minFDE1: 28.05403, val_minFDE6: 27.67638
[2025-01-13 18:15:44,746][root][INFO] - 
[Epoch 0] train_loss: 7.93787, train_reg_loss: 3.41316, train_cls_loss: 0.98768, train_prediction_losss: 3.07291, train_diffusion_loss: 0.46412, train_MR: 0.60365, train_minADE1: 13.21402, train_minADE6: 12.61684, train_minFDE1: 28.72169, train_minFDE6: 27.72391
[2025-01-13 18:33:11,330][root][INFO] - 
[Epoch 1] val_loss: 7.78488, val_reg_loss: 1.77162, val_cls_loss: 1.30389, val_prediction_losss: 1.26756, val_diffusion_loss: 3.44181, val_MR: 0.67178, val_minADE1: 7.03782, val_minADE6: 6.91594, val_minFDE1: 20.63509, val_minFDE6: 17.68251
[2025-01-13 18:50:34,621][root][INFO] - 
[Epoch 1] val_loss: 9.37220, val_reg_loss: 1.31158, val_cls_loss: 2.69782, val_prediction_losss: 0.81675, val_diffusion_loss: 4.54604, val_MR: 0.65526, val_minADE1: 5.54320, val_minADE6: 5.01426, val_minFDE1: 16.87078, val_minFDE6: 10.92974
[2025-01-13 18:50:36,304][root][INFO] - 
[Epoch 1] train_loss: 5.45596, train_reg_loss: 2.12595, train_cls_loss: 0.87499, train_prediction_losss: 1.81915, train_diffusion_loss: 0.63587, train_MR: 0.60034, train_minADE1: 8.53255, train_minADE6: 7.93338, train_minFDE1: 20.43213, train_minFDE6: 19.19179
[2025-01-13 19:08:03,676][root][INFO] - 
[Epoch 2] val_loss: 9.30864, val_reg_loss: 0.94140, val_cls_loss: 2.93069, val_prediction_losss: 0.56557, val_diffusion_loss: 4.87099, val_MR: 0.62250, val_minADE1: 4.56462, val_minADE6: 3.59953, val_minFDE1: 13.13273, val_minFDE6: 6.21379
[2025-01-13 19:25:32,825][root][INFO] - 
[Epoch 2] val_loss: 9.55434, val_reg_loss: 0.74575, val_cls_loss: 3.52618, val_prediction_losss: 0.48519, val_diffusion_loss: 4.79723, val_MR: 0.63334, val_minADE1: 5.25663, val_minADE6: 2.89056, val_minFDE1: 17.38331, val_minFDE6: 5.23311
[2025-01-13 19:25:34,072][root][INFO] - 
[Epoch 2] train_loss: 3.49606, train_reg_loss: 1.06766, train_cls_loss: 0.72568, train_prediction_losss: 0.84857, train_diffusion_loss: 0.85415, train_MR: 0.58011, train_minADE1: 4.59629, train_minADE6: 4.07753, train_minFDE1: 10.40780, train_minFDE6: 9.20033
[2025-01-13 19:43:02,662][root][INFO] - 
[Epoch 3] val_loss: 9.49281, val_reg_loss: 0.83181, val_cls_loss: 3.59868, val_prediction_losss: 0.45190, val_diffusion_loss: 4.61043, val_MR: 0.59715, val_minADE1: 6.50609, val_minADE6: 3.17323, val_minFDE1: 21.00506, val_minFDE6: 5.57783
[2025-01-13 20:00:27,945][root][INFO] - 
[Epoch 3] val_loss: 9.29343, val_reg_loss: 0.76851, val_cls_loss: 3.40680, val_prediction_losss: 0.41772, val_diffusion_loss: 4.70039, val_MR: 0.61197, val_minADE1: 8.56313, val_minADE6: 2.98522, val_minFDE1: 23.40214, val_minFDE6: 4.65075
[2025-01-13 20:00:29,644][root][INFO] - 
[Epoch 3] train_loss: 2.91848, train_reg_loss: 0.86883, train_cls_loss: 0.54538, train_prediction_losss: 0.63447, train_diffusion_loss: 0.86980, train_MR: 0.56488, train_minADE1: 3.80055, train_minADE6: 3.39501, train_minFDE1: 8.11671, train_minFDE6: 7.10216
[2025-01-13 20:17:59,905][root][INFO] - 
[Epoch 4] val_loss: 8.57112, val_reg_loss: 0.75945, val_cls_loss: 2.78202, val_prediction_losss: 0.40778, val_diffusion_loss: 4.62187, val_MR: 0.51634, val_minADE1: 11.63378, val_minADE6: 2.68992, val_minFDE1: 29.93540, val_minFDE6: 4.37574
[2025-01-13 20:35:22,904][root][INFO] - 
[Epoch 4] val_loss: 9.98024, val_reg_loss: 0.91367, val_cls_loss: 4.04684, val_prediction_losss: 0.40967, val_diffusion_loss: 4.61007, val_MR: 0.61339, val_minADE1: 11.61879, val_minADE6: 3.26825, val_minFDE1: 29.32452, val_minFDE6: 4.73566
[2025-01-13 20:35:24,154][root][INFO] - 
[Epoch 4] train_loss: 2.69138, train_reg_loss: 0.79415, train_cls_loss: 0.45857, train_prediction_losss: 0.56991, train_diffusion_loss: 0.86875, train_MR: 0.55660, train_minADE1: 3.49431, train_minADE6: 3.13837, train_minFDE1: 7.40828, train_minFDE6: 6.49306
[2025-01-13 20:52:52,850][root][INFO] - 
[Epoch 5] val_loss: 9.45071, val_reg_loss: 0.73580, val_cls_loss: 3.53619, val_prediction_losss: 0.39846, val_diffusion_loss: 4.78027, val_MR: 0.57386, val_minADE1: 13.49411, val_minADE6: 2.71723, val_minFDE1: 31.05648, val_minFDE6: 4.23381
[2025-01-13 21:10:16,874][root][INFO] - 
[Epoch 5] val_loss: 9.32808, val_reg_loss: 0.82660, val_cls_loss: 3.68542, val_prediction_losss: 0.38281, val_diffusion_loss: 4.43325, val_MR: 0.51065, val_minADE1: 13.93391, val_minADE6: 2.82562, val_minFDE1: 30.45422, val_minFDE6: 3.91025
[2025-01-13 21:10:18,141][root][INFO] - 
[Epoch 5] train_loss: 2.57823, train_reg_loss: 0.76486, train_cls_loss: 0.41226, train_prediction_losss: 0.53709, train_diffusion_loss: 0.86402, train_MR: 0.55003, train_minADE1: 3.35320, train_minADE6: 3.03920, train_minFDE1: 7.06995, train_minFDE6: 6.24602
[2025-01-13 21:27:48,883][root][INFO] - 
[Epoch 6] val_loss: 9.13171, val_reg_loss: 0.72785, val_cls_loss: 3.48411, val_prediction_losss: 0.37510, val_diffusion_loss: 4.54466, val_MR: 0.49555, val_minADE1: 15.20483, val_minADE6: 2.51973, val_minFDE1: 32.96421, val_minFDE6: 3.77051
[2025-01-13 21:45:15,198][root][INFO] - 
[Epoch 6] val_loss: 8.62381, val_reg_loss: 0.74036, val_cls_loss: 3.19391, val_prediction_losss: 0.36773, val_diffusion_loss: 4.32181, val_MR: 0.51136, val_minADE1: 15.32315, val_minADE6: 2.70855, val_minFDE1: 31.71157, val_minFDE6: 4.21895
[2025-01-13 21:45:17,339][root][INFO] - 
[Epoch 6] train_loss: 2.52858, train_reg_loss: 0.73433, train_cls_loss: 0.41758, train_prediction_losss: 0.51233, train_diffusion_loss: 0.86434, train_MR: 0.54447, train_minADE1: 3.23309, train_minADE6: 2.93096, train_minFDE1: 6.81301, train_minFDE6: 6.00614
[2025-01-13 22:02:49,492][root][INFO] - 
[Epoch 7] val_loss: 9.14305, val_reg_loss: 0.76947, val_cls_loss: 3.56082, val_prediction_losss: 0.36829, val_diffusion_loss: 4.44447, val_MR: 0.49423, val_minADE1: 14.65770, val_minADE6: 2.72224, val_minFDE1: 31.28110, val_minFDE6: 3.67982
[2025-01-13 22:20:12,377][root][INFO] - 
[Epoch 7] val_loss: 9.61976, val_reg_loss: 0.77348, val_cls_loss: 3.88695, val_prediction_losss: 0.35071, val_diffusion_loss: 4.60862, val_MR: 0.48132, val_minADE1: 15.70186, val_minADE6: 2.74805, val_minFDE1: 33.18040, val_minFDE6: 3.51949
[2025-01-13 22:20:13,699][root][INFO] - 
[Epoch 7] train_loss: 2.43986, train_reg_loss: 0.70487, train_cls_loss: 0.37900, train_prediction_losss: 0.49402, train_diffusion_loss: 0.86198, train_MR: 0.53874, train_minADE1: 3.10645, train_minADE6: 2.83059, train_minFDE1: 6.53167, train_minFDE6: 5.77622
[2025-01-13 22:37:43,136][root][INFO] - 
[Epoch 8] val_loss: 8.84173, val_reg_loss: 0.75411, val_cls_loss: 3.54505, val_prediction_losss: 0.35227, val_diffusion_loss: 4.19029, val_MR: 0.60777, val_minADE1: 15.49425, val_minADE6: 2.77983, val_minFDE1: 32.79234, val_minFDE6: 4.23755
[2025-01-13 22:57:48,456][root][INFO] - 
[Epoch 8] val_loss: 8.95570, val_reg_loss: 0.73191, val_cls_loss: 3.39035, val_prediction_losss: 0.36653, val_diffusion_loss: 4.46692, val_MR: 0.45467, val_minADE1: 15.50448, val_minADE6: 2.48690, val_minFDE1: 32.62604, val_minFDE6: 3.43322
[2025-01-13 22:57:49,712][root][INFO] - 
[Epoch 8] train_loss: 2.39072, train_reg_loss: 0.68728, train_cls_loss: 0.36307, train_prediction_losss: 0.48112, train_diffusion_loss: 0.85926, train_MR: 0.53568, train_minADE1: 3.04230, train_minADE6: 2.77381, train_minFDE1: 6.38607, train_minFDE6: 5.64370
[2025-01-13 23:18:53,896][root][INFO] - 
[Epoch 9] val_loss: 9.87260, val_reg_loss: 0.91954, val_cls_loss: 3.71999, val_prediction_losss: 0.35021, val_diffusion_loss: 4.88285, val_MR: 0.49565, val_minADE1: 15.85568, val_minADE6: 2.95916, val_minFDE1: 33.42707, val_minFDE6: 3.96378
[2025-01-13 23:58:06,323][root][INFO] - 
[Epoch 9] val_loss: 9.56925, val_reg_loss: 0.72479, val_cls_loss: 3.82916, val_prediction_losss: 0.34594, val_diffusion_loss: 4.66935, val_MR: 0.45177, val_minADE1: 15.93101, val_minADE6: 2.54632, val_minFDE1: 33.26917, val_minFDE6: 3.36492
[2025-01-13 23:58:08,300][root][INFO] - 
[Epoch 9] train_loss: 2.36604, train_reg_loss: 0.68010, train_cls_loss: 0.36365, train_prediction_losss: 0.46927, train_diffusion_loss: 0.85302, train_MR: 0.53321, train_minADE1: 2.97590, train_minADE6: 2.74914, train_minFDE1: 6.26076, train_minFDE6: 5.62540
[2025-01-14 00:46:15,357][root][INFO] - 
[Epoch 10] val_loss: 9.10699, val_reg_loss: 0.84177, val_cls_loss: 3.47609, val_prediction_losss: 0.34281, val_diffusion_loss: 4.44631, val_MR: 0.47381, val_minADE1: 15.91646, val_minADE6: 2.80512, val_minFDE1: 32.83031, val_minFDE6: 3.76945
[2025-01-14 01:12:00,970][root][INFO] - 
[Epoch 10] val_loss: 9.13360, val_reg_loss: 0.78177, val_cls_loss: 3.51083, val_prediction_losss: 0.34308, val_diffusion_loss: 4.49791, val_MR: 0.47601, val_minADE1: 16.03491, val_minADE6: 2.67800, val_minFDE1: 33.19468, val_minFDE6: 3.80969
[2025-01-14 01:12:02,475][root][INFO] - 
[Epoch 10] train_loss: 2.33144, train_reg_loss: 0.66171, train_cls_loss: 0.35534, train_prediction_losss: 0.45999, train_diffusion_loss: 0.85440, train_MR: 0.53018, train_minADE1: 2.90311, train_minADE6: 2.68295, train_minFDE1: 6.10138, train_minFDE6: 5.48362
[2025-01-14 01:37:52,853][root][INFO] - 
[Epoch 11] val_loss: 9.32285, val_reg_loss: 0.84611, val_cls_loss: 3.68543, val_prediction_losss: 0.34251, val_diffusion_loss: 4.44881, val_MR: 0.48944, val_minADE1: 15.98461, val_minADE6: 2.73861, val_minFDE1: 33.37150, val_minFDE6: 3.55642
[2025-01-14 02:03:32,994][root][INFO] - 
[Epoch 11] val_loss: 8.97023, val_reg_loss: 0.74652, val_cls_loss: 3.41472, val_prediction_losss: 0.34428, val_diffusion_loss: 4.46472, val_MR: 0.47845, val_minADE1: 16.34130, val_minADE6: 2.51882, val_minFDE1: 33.78511, val_minFDE6: 3.75312
[2025-01-14 02:03:34,306][root][INFO] - 
[Epoch 11] train_loss: 2.41105, train_reg_loss: 0.66510, train_cls_loss: 0.43980, train_prediction_losss: 0.45098, train_diffusion_loss: 0.85518, train_MR: 0.52792, train_minADE1: 2.90064, train_minADE6: 2.69092, train_minFDE1: 6.11823, train_minFDE6: 5.55842
[2025-01-14 02:29:25,015][root][INFO] - 
[Epoch 12] val_loss: 9.14296, val_reg_loss: 0.83370, val_cls_loss: 3.61348, val_prediction_losss: 0.32919, val_diffusion_loss: 4.36658, val_MR: 0.48190, val_minADE1: 16.20932, val_minADE6: 2.83365, val_minFDE1: 33.20111, val_minFDE6: 3.80317
[2025-01-14 02:55:14,637][root][INFO] - 
[Epoch 12] val_loss: 8.47365, val_reg_loss: 0.87494, val_cls_loss: 2.91648, val_prediction_losss: 0.33155, val_diffusion_loss: 4.35067, val_MR: 0.49796, val_minADE1: 16.33481, val_minADE6: 2.89438, val_minFDE1: 34.48125, val_minFDE6: 4.58851
[2025-01-14 02:55:16,625][root][INFO] - 
[Epoch 12] train_loss: 2.43285, train_reg_loss: 0.65854, train_cls_loss: 0.46693, train_prediction_losss: 0.44550, train_diffusion_loss: 0.86187, train_MR: 0.52384, train_minADE1: 2.90659, train_minADE6: 2.66440, train_minFDE1: 6.14601, train_minFDE6: 5.50248
[2025-01-14 03:20:56,825][root][INFO] - 
[Epoch 13] val_loss: 8.97023, val_reg_loss: 0.82095, val_cls_loss: 3.25023, val_prediction_losss: 0.32711, val_diffusion_loss: 4.57195, val_MR: 0.47122, val_minADE1: 16.33916, val_minADE6: 2.67397, val_minFDE1: 34.16258, val_minFDE6: 3.86144
[2025-01-14 03:46:44,973][root][INFO] - 
[Epoch 13] val_loss: 9.60151, val_reg_loss: 0.96161, val_cls_loss: 3.77734, val_prediction_losss: 0.33841, val_diffusion_loss: 4.52415, val_MR: 0.48302, val_minADE1: 16.53286, val_minADE6: 3.14678, val_minFDE1: 34.15035, val_minFDE6: 4.18726
[2025-01-14 03:46:46,205][root][INFO] - 
[Epoch 13] train_loss: 2.40055, train_reg_loss: 0.64587, train_cls_loss: 0.45229, train_prediction_losss: 0.43938, train_diffusion_loss: 0.86300, train_MR: 0.52327, train_minADE1: 2.86208, train_minADE6: 2.61547, train_minFDE1: 6.06791, train_minFDE6: 5.39246
[2025-01-14 04:12:42,099][root][INFO] - 
[Epoch 14] val_loss: 8.69328, val_reg_loss: 0.85215, val_cls_loss: 3.30910, val_prediction_losss: 0.32866, val_diffusion_loss: 4.20338, val_MR: 0.49528, val_minADE1: 16.06549, val_minADE6: 2.83899, val_minFDE1: 33.64215, val_minFDE6: 4.57234
[2025-01-14 04:34:21,932][root][INFO] - 
[Epoch 14] val_loss: 9.31149, val_reg_loss: 0.78562, val_cls_loss: 3.67123, val_prediction_losss: 0.34501, val_diffusion_loss: 4.50964, val_MR: 0.46881, val_minADE1: 15.96643, val_minADE6: 2.73737, val_minFDE1: 33.57792, val_minFDE6: 3.89043
[2025-01-14 04:34:23,132][root][INFO] - 
[Epoch 14] train_loss: 2.37234, train_reg_loss: 0.63387, train_cls_loss: 0.44325, train_prediction_losss: 0.43401, train_diffusion_loss: 0.86120, train_MR: 0.52147, train_minADE1: 2.82834, train_minADE6: 2.57524, train_minFDE1: 5.99386, train_minFDE6: 5.31112
[2025-01-14 04:51:50,621][root][INFO] - 
[Epoch 15] val_loss: 9.13666, val_reg_loss: 0.85762, val_cls_loss: 3.52892, val_prediction_losss: 0.32036, val_diffusion_loss: 4.42975, val_MR: 0.47437, val_minADE1: 16.21989, val_minADE6: 2.94159, val_minFDE1: 34.33327, val_minFDE6: 4.19737
[2025-01-14 05:09:14,383][root][INFO] - 
[Epoch 15] val_loss: 9.14789, val_reg_loss: 0.88401, val_cls_loss: 3.52927, val_prediction_losss: 0.32654, val_diffusion_loss: 4.40807, val_MR: 0.48221, val_minADE1: 16.09780, val_minADE6: 3.05415, val_minFDE1: 33.71650, val_minFDE6: 4.46480
[2025-01-14 05:09:15,602][root][INFO] - 
[Epoch 15] train_loss: 2.33772, train_reg_loss: 0.62382, train_cls_loss: 0.42615, train_prediction_losss: 0.42920, train_diffusion_loss: 0.85854, train_MR: 0.51886, train_minADE1: 2.79320, train_minADE6: 2.54108, train_minFDE1: 5.92889, train_minFDE6: 5.25504
[2025-01-14 05:26:42,920][root][INFO] - 
[Epoch 16] val_loss: 9.18054, val_reg_loss: 0.94293, val_cls_loss: 3.42715, val_prediction_losss: 0.31923, val_diffusion_loss: 4.49122, val_MR: 0.47415, val_minADE1: 16.18752, val_minADE6: 3.09530, val_minFDE1: 34.28238, val_minFDE6: 4.43535
[2025-01-14 05:44:04,323][root][INFO] - 
[Epoch 16] val_loss: 8.89448, val_reg_loss: 0.97835, val_cls_loss: 3.33318, val_prediction_losss: 0.31523, val_diffusion_loss: 4.26773, val_MR: 0.49469, val_minADE1: 16.11431, val_minADE6: 3.39189, val_minFDE1: 33.51790, val_minFDE6: 4.79762
[2025-01-14 05:44:05,586][root][INFO] - 
[Epoch 16] train_loss: 2.29543, train_reg_loss: 0.61447, train_cls_loss: 0.39961, train_prediction_losss: 0.42515, train_diffusion_loss: 0.85621, train_MR: 0.51372, train_minADE1: 2.74446, train_minADE6: 2.50946, train_minFDE1: 5.81175, train_minFDE6: 5.16162
[2025-01-14 06:01:30,266][root][INFO] - 
[Epoch 17] val_loss: 9.05462, val_reg_loss: 0.97697, val_cls_loss: 3.42166, val_prediction_losss: 0.31751, val_diffusion_loss: 4.33849, val_MR: 0.49086, val_minADE1: 16.17975, val_minADE6: 3.35093, val_minFDE1: 33.97001, val_minFDE6: 4.75736
[2025-01-14 06:18:54,892][root][INFO] - 
[Epoch 17] val_loss: 9.15134, val_reg_loss: 1.01537, val_cls_loss: 3.37995, val_prediction_losss: 0.31838, val_diffusion_loss: 4.43764, val_MR: 0.47496, val_minADE1: 16.19450, val_minADE6: 3.38660, val_minFDE1: 34.24509, val_minFDE6: 4.87549
[2025-01-14 06:18:56,115][root][INFO] - 
[Epoch 17] train_loss: 2.25006, train_reg_loss: 0.60423, train_cls_loss: 0.37128, train_prediction_losss: 0.42228, train_diffusion_loss: 0.85227, train_MR: 0.51004, train_minADE1: 2.69670, train_minADE6: 2.47620, train_minFDE1: 5.68613, train_minFDE6: 5.06781
[2025-01-14 06:36:23,992][root][INFO] - 
[Epoch 18] val_loss: 9.06488, val_reg_loss: 1.02371, val_cls_loss: 3.32667, val_prediction_losss: 0.31547, val_diffusion_loss: 4.39904, val_MR: 0.47659, val_minADE1: 16.16440, val_minADE6: 3.44183, val_minFDE1: 34.06475, val_minFDE6: 4.89444
[2025-01-14 06:53:48,359][root][INFO] - 
[Epoch 18] val_loss: 9.13041, val_reg_loss: 0.96147, val_cls_loss: 3.46990, val_prediction_losss: 0.31595, val_diffusion_loss: 4.38308, val_MR: 0.47780, val_minADE1: 16.17044, val_minADE6: 3.21904, val_minFDE1: 34.07363, val_minFDE6: 4.57780
[2025-01-14 06:53:49,616][root][INFO] - 
[Epoch 18] train_loss: 2.22402, train_reg_loss: 0.59862, train_cls_loss: 0.35298, train_prediction_losss: 0.42025, train_diffusion_loss: 0.85216, train_MR: 0.50793, train_minADE1: 2.67812, train_minADE6: 2.45836, train_minFDE1: 5.65146, train_minFDE6: 5.03170
[2025-01-14 07:11:12,106][root][INFO] - 
[Epoch 19] val_loss: 9.19827, val_reg_loss: 0.94555, val_cls_loss: 3.49328, val_prediction_losss: 0.31409, val_diffusion_loss: 4.44535, val_MR: 0.46600, val_minADE1: 16.10985, val_minADE6: 3.19476, val_minFDE1: 34.12660, val_minFDE6: 4.44184
[2025-01-14 07:28:34,314][root][INFO] - 
[Epoch 19] val_loss: 9.12355, val_reg_loss: 0.97656, val_cls_loss: 3.44610, val_prediction_losss: 0.31463, val_diffusion_loss: 4.38626, val_MR: 0.47659, val_minADE1: 16.08540, val_minADE6: 3.31732, val_minFDE1: 34.21136, val_minFDE6: 4.71546
[2025-01-14 07:28:35,560][root][INFO] - 
[Epoch 19] train_loss: 2.21163, train_reg_loss: 0.59182, train_cls_loss: 0.34983, train_prediction_losss: 0.41877, train_diffusion_loss: 0.85121, train_MR: 0.50564, train_minADE1: 2.64815, train_minADE6: 2.43674, train_minFDE1: 5.60024, train_minFDE6: 4.99392






























wandb: Run history:                                                                                                                                                               
wandb:                      epoch ▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████                                                                                                        
wandb:      loss/train_loss_epoch █▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁                                                                                                                            
wandb:       loss/train_loss_step █▆▅▅▄▂▂▂▃▂▂▁▂▂▁▁▂▁▁▁▂▂▁▁▂▁▂▁▂▂▁▁▂▁▂▁▂▁▁▁                                                                                                        
wandb:        loss/val_loss_epoch ▃▂▁▆▆▇▆▆▄█▆▆▅▄▅▇▄▅█▇▅▅▆▅▅▃▅▇▄▆▅▅▅▅▅▅▅▅▆▅                                                                                                        
wandb:         loss/val_loss_step ▄▂▃▄▃▅▆▅▅▅▆▅▄▅█▆▃▁▆▆▃▄▂▄▄▄▄▄▁▅▆▄▅▄▁▇▄▂▄▆                                                                                                        
wandb:               lr-AdamW/pg1 ▃▆████▇▇▇▆▅▅▄▄▃▂▂▁▁▁                                                                                                                            
wandb:               lr-AdamW/pg2 ▃▆████▇▇▇▆▅▅▄▄▃▂▂▁▁▁                                                                                                                            
wandb:  objectives/train_cls_loss █▇▅▃▂▂▂▁▁▁▁▂▂▂▂▂▂▁▁▁                                                                                                                            
wandb: objectives/train_diff_loss ▁▄██████████████████                                                                                                                            
wandb:      objectives/train_loss █▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁                                                                                                                            
wandb: objectives/train_pred_loss █▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁                                                                                                                            
wandb:  objectives/train_reg_loss █▅▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁                                                                                                                            
wandb:    objectives/val_cls_loss ▁▁▂▅▅▇▇▇▅█▇▇▇▆▇█▇▇▇█▇▇▇▇▇▅▆▇▆▇▇▇▇▆▇▆▆▇▇▇                                                                                                        
wandb:   objectives/val_diff_loss ▁▂▅▇██▇█▇▇█▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇                                                                                                        
wandb:        objectives/val_loss ▃▂▁▆▆▇▆▆▄█▆▆▅▄▅▇▄▅█▇▅▅▆▅▅▃▅▇▄▆▅▅▅▅▅▅▅▅▆▅                                                                                                        
wandb:   objectives/val_pred_loss █▇▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁                                                                                                        
wandb:    objectives/val_reg_loss █▇▄▃▂▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▂▂▂▂▂▂▂▂                                                                                                        
wandb:                   train/MR ██▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁                                                                                                                            
wandb:              train/minADE1 █▅▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁                                                                                                                            
wandb:              train/minADE6 █▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁                                                                                                                            
wandb:              train/minFDE1 █▅▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁                    
wandb:              train/minFDE6 █▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁                    
wandb:        trainer/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:                     val/MR █▇▇▇▆▆▅▅▃▅▄▃▂▃▂▂▅▁▂▁▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▂
wandb:                val/minADE1 ▆▅▂▂▁▁▂▃▅▅▆▆▇▇▇█▇▇██████████████████████
wandb:                val/minADE6 █▇▄▃▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▁▁▂
wandb:                val/minFDE1 ▆▆▃▂▁▂▄▄▇▆▇▇█▇▇█▇▇██▇███████████████████
wandb:                val/minFDE6 ██▅▃▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb: Run summary:
wandb:                      epoch 19
wandb:      loss/train_loss_epoch 2.21163
wandb:       loss/train_loss_step 2.10555
wandb:        loss/val_loss_epoch 9.12355
wandb:         loss/val_loss_step 9.16175
wandb:               lr-AdamW/pg1 0.0
wandb:               lr-AdamW/pg2 0.0
wandb:  objectives/train_cls_loss 0.34983
wandb: objectives/train_diff_loss 0.85121
wandb:      objectives/train_loss 2.21163
wandb: objectives/train_pred_loss 0.41877
wandb:  objectives/train_reg_loss 0.59182
wandb:    objectives/val_cls_loss 3.4461
wandb:   objectives/val_diff_loss 4.38626
wandb:        objectives/val_loss 9.12355
wandb:   objectives/val_pred_loss 0.31463
wandb:    objectives/val_reg_loss 0.97656
wandb:                   train/MR 0.50564
wandb:              train/minADE1 2.64815
wandb:              train/minADE6 2.43674
wandb:              train/minFDE1 5.60024
wandb:              train/minFDE6 4.99392
wandb:        trainer/global_step 82739
wandb:                     val/MR 0.47659
wandb:                val/minADE1 16.0854
wandb:                val/minADE6 3.31732
wandb:                val/minFDE1 34.21136
wandb:                val/minFDE6 4.71546